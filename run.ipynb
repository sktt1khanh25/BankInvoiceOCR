{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. import các thư viện cần thiết"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "import argparse\n",
    "import os\n",
    "import platform\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import cudnn_affine_grid_generator\n",
    "import cv2\n",
    "from models.common import DetectMultiBackend\n",
    "from utils.dataloaders import IMG_FORMATS, VID_FORMATS, LoadImages, LoadStreams\n",
    "from utils.general import (LOGGER, check_file, check_img_size, check_imshow, check_requirements, colorstr, \n",
    "                           increment_path, non_max_suppression, print_args, strip_optimizer, xyxy2xywh)\n",
    "from utils.plots import Annotator, colors, save_one_box\n",
    "from utils.torch_utils import select_device, smart_inference_mode, time_sync\n",
    "\n",
    "def scale_coords(img1_shape, coords, img0_shape, ratio_pad=None):\n",
    "    # Rescale coords (xyxy) from img1_shape to img0_shape\n",
    "    if ratio_pad is None:  # calculate from img0_shape\n",
    "        gain = min(img1_shape[0] / img0_shape[0], img1_shape[1] / img0_shape[1])  # gain  = old / new\n",
    "        pad = (img1_shape[1] - img0_shape[1] * gain) / 2, (img1_shape[0] - img0_shape[0] * gain) / 2  # wh padding\n",
    "    else:\n",
    "        gain = ratio_pad[0][0]\n",
    "        pad = ratio_pad[1]\n",
    "\n",
    "    coords[:, [0, 2]] -= pad[0]  # x padding\n",
    "    coords[:, [1, 3]] -= pad[1]  # y padding\n",
    "    coords[:, :4] /= gain\n",
    "    clip_coords(coords, img0_shape)\n",
    "    return coords\n",
    "\n",
    "def clip_coords(boxes, shape):\n",
    "    # Clip bounding xyxy bounding boxes to image shape (height, width)\n",
    "    if isinstance(boxes, torch.Tensor):  # faster individually\n",
    "        boxes[:, 0].clamp_(0, shape[1])  # x1\n",
    "        boxes[:, 1].clamp_(0, shape[0])  # y1\n",
    "        boxes[:, 2].clamp_(0, shape[1])  # x2\n",
    "        boxes[:, 3].clamp_(0, shape[0])  # y2\n",
    "    else:  # np.array (faster grouped)\n",
    "        boxes[:, [0, 2]] = boxes[:, [0, 2]].clip(0, shape[1])  # x1, x2\n",
    "        boxes[:, [1, 3]] = boxes[:, [1, 3]].clip(0, shape[0])  # y1, y2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. dùng model yolov5 để phân vùng ảnh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2023-5-22 Python-3.10.6 torch-2.0.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7029004 parameters, 0 gradients\n",
      "image 1/1 E:\\yolov5\\data\\images\\test.jpg: 640x320 1 STK ch, 1 ni dung chuyn khon, 1 s tin, 1 thi gian chuyn khon, 1 tn ngi nhn, Done. (0.159s)\n",
      "Speed: 4.0ms pre-process, 158.6ms inference, 11.0ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1m\\runs\\detect\\exp2\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "=======\n",
      "\n",
      "[[     190.12      424.46      301.77      450.17     0.95444           2]\n",
      " [      107.7      187.79      212.35      206.27     0.87356           3]\n",
      " [     213.78      293.07      303.58      306.58     0.86338           1]\n",
      " [     168.99      254.42      298.86      268.38     0.82526           6]\n",
      " [     105.16      209.91      214.82      220.84     0.68066           4]]\n",
      "save crop:  True\n"
     ]
    }
   ],
   "source": [
    "@smart_inference_mode()\n",
    "def run(\n",
    "        weights='E:/yolov5/runs/train/exp2/weights/best.pt',  # model.pt path(s)\n",
    "        source='data/images/test.jpg',  # file/dir/URL/glob, 0 for webcam\n",
    "        data='data/custom_data.yaml',  # dataset.yaml path\n",
    "        imgsz=(640, 640),  # inference size (height, width)\n",
    "        conf_thres=0.33,  # confidence threshold\n",
    "        iou_thres=0.45,  # NMS IOU threshold\n",
    "        max_det=1000,  # maximum detections per image\n",
    "        device='',  # cuda device, i.e. 0 or 0,1,2,3 or cpu\n",
    "        view_img=False,  # show results\n",
    "        save_txt=False,  # save results to *.txt\n",
    "        save_conf=False,  # save confidences in --save-txt labels\n",
    "        save_crop=True,  # save cropped prediction boxes\n",
    "        nosave=False,  # do not save images/videos\n",
    "        classes=None,  # filter by class: --class 0, or --class 0 2 3\n",
    "        agnostic_nms=False,  # class-agnostic NMS\n",
    "        augment=False,  # augmented inference\n",
    "        visualize=False,  # visualize features\n",
    "        update=False,  # update all models\n",
    "        project='/runs/detect/exp2',  # save results to project/name\n",
    "        #name='exp',  # save results to project/name\n",
    "        exist_ok=False,  # existing project/name ok, do not increment\n",
    "        line_thickness=3,  # bounding box thickness (pixels)\n",
    "        hide_labels=False,  # hide labels\n",
    "        hide_conf=False,  # hide confidences\n",
    "        half=False,  # use FP16 half-precision inference\n",
    "        dnn=False,  # use OpenCV DNN for ONNX inference\n",
    "):\n",
    "    source = str(source)\n",
    "    save_img = not nosave and not source.endswith('.txt')  # save inference images\n",
    "    is_file = Path(source).suffix[1:] in (IMG_FORMATS + VID_FORMATS)\n",
    "    is_url = source.lower().startswith(('rtsp://', 'rtmp://', 'http://', 'https://'))\n",
    "    webcam = source.isnumeric() or source.endswith('.txt') or (is_url and not is_file)\n",
    "    if is_url and is_file:\n",
    "        source = check_file(source)  # download\n",
    "\n",
    "    # Directories\n",
    "    save_dir = increment_path(Path(project), exist_ok=exist_ok)  # increment run\n",
    "    (save_dir / 'labels' if save_txt else save_dir).mkdir(parents=True, exist_ok=True)  # make dir\n",
    "\n",
    "    # Load model\n",
    "    device = select_device(device)\n",
    "    model = DetectMultiBackend(weights, device=device, dnn=dnn, data=data, fp16=half)\n",
    "    stride, names, pt = model.stride, model.names, model.pt\n",
    "    imgsz = check_img_size(imgsz, s=stride)  # check image size\n",
    "\n",
    "    # Dataloader\n",
    "    if webcam:\n",
    "        view_img = check_imshow()\n",
    "        cudnn_affine_grid_generator.benchmark = True  # set True to speed up constant image size inference\n",
    "        dataset = LoadStreams(source, img_size=imgsz, stride=stride, auto=pt)\n",
    "        bs = len(dataset)  # batch_size\n",
    "    else:\n",
    "        dataset = LoadImages(source, img_size=imgsz, stride=stride, auto=pt)\n",
    "        bs = 1  # batch_size\n",
    "    vid_path, vid_writer = [None] * bs, [None] * bs\n",
    "\n",
    "    # Run inference\n",
    "    model.warmup(imgsz=(1 if pt else bs, 3, *imgsz))  # warmup\n",
    "    seen, windows, dt = 0, [], [0.0, 0.0, 0.0]\n",
    "    for path, im, im0s, vid_cap, s in dataset:\n",
    "        t1 = time_sync()\n",
    "        im = torch.from_numpy(im).to(device)\n",
    "        im = im.half() if model.fp16 else im.float()  # uint8 to fp16/32\n",
    "        im /= 255  # 0 - 255 to 0.0 - 1.0\n",
    "        if len(im.shape) == 3:\n",
    "            im = im[None]  # expand for batch dim\n",
    "        t2 = time_sync()\n",
    "        dt[0] += t2 - t1\n",
    "\n",
    "        # Inference\n",
    "        visualize = increment_path(save_dir / Path(path).stem, mkdir=True) if visualize else False\n",
    "        pred = model(im, augment=augment, visualize=visualize)\n",
    "        t3 = time_sync()\n",
    "        dt[1] += t3 - t2\n",
    "\n",
    "        # NMS\n",
    "        pred = non_max_suppression(pred, conf_thres, iou_thres, classes, agnostic_nms, max_det=max_det)\n",
    "        dt[2] += time_sync() - t3\n",
    "\n",
    "        # Second-stage classifier (optional)\n",
    "        # pred = utils.general.apply_classifier(pred, classifier_model, im, im0s)\n",
    "\n",
    "        # Process predictions\n",
    "        for i, det in enumerate(pred):\n",
    "            print(i)\n",
    "            print('=======\\n')\n",
    "            print(det.cpu().detach().numpy())\n",
    "            seen += 1\n",
    "            if webcam:  # batch_size >= 1\n",
    "                p, im0, frame = path[i], im0s[i].copy(), dataset.count\n",
    "                s += f'{i}: '\n",
    "            else:\n",
    "                p, im0, frame = path, im0s.copy(), getattr(dataset, 'frame', 0)\n",
    "\n",
    "            p = Path(p)  # to Path\n",
    "            save_path = str(save_dir / p.name)  # im.jpg\n",
    "            txt_path = str(save_dir / 'labels' / p.stem) + ('' if dataset.mode == 'image' else f'_{frame}')  # im.txt\n",
    "            s += '%gx%g ' % im.shape[2:]  # print string\n",
    "            gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]  # normalization gain whwh\n",
    "            imc = im0.copy() if save_crop else im0  # for save_crop\n",
    "            annotator = Annotator(im0, line_width=line_thickness, example=str(names))\n",
    "            print('save crop: ',save_crop)\n",
    "            if len(det):\n",
    "                # Rescale boxes from img_size to im0 size\n",
    "                det[:, :4] = scale_coords(im.shape[2:], det[:, :4], im0.shape).round()\n",
    "\n",
    "                # Print results\n",
    "                for c in det[:, -1].unique():\n",
    "                    n = (det[:, -1] == c).sum()  # detections per class\n",
    "                    s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \"  # add to string\n",
    "\n",
    "                # Write results\n",
    "                for *xyxy, conf, cls in reversed(det):\n",
    "                    if save_txt:  # Write to file\n",
    "                        xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()  # normalized xywh\n",
    "                        line = (cls, *xywh, conf) if save_conf else (cls, *xywh)  # label format\n",
    "                        with open(f'{txt_path}.txt', 'a') as f:\n",
    "                            f.write(('%g ' * len(line)).rstrip() % line + '\\n')\n",
    "\n",
    "                    if save_img or save_crop or view_img:  # Add bbox to image\n",
    "                        c = int(cls)  # integer class\n",
    "                        label = None if hide_labels else (names[c] if hide_conf else f'{names[c]} {conf:.2f}')\n",
    "                        annotator.box_label(xyxy, label, color=colors(c, True))\n",
    "                    if save_crop:\n",
    "                        save_one_box(xyxy, imc, file=save_dir / 'crops' / names[c] / f'{p.stem}.jpg', BGR=True)\n",
    "\n",
    "            # Stream results\n",
    "            im0 = annotator.result()\n",
    "            if view_img:\n",
    "                if platform.system() == 'Linux' and p not in windows:\n",
    "                    windows.append(p)\n",
    "                    cv2.namedWindow(str(p), cv2.WINDOW_NORMAL | cv2.WINDOW_KEEPRATIO)  # allow window resize (Linux)\n",
    "                    cv2.resizeWindow(str(p), im0.shape[1], im0.shape[0])\n",
    "                cv2.imshow(str(p), im0)\n",
    "                cv2.waitKey(1)  # 1 millisecond\n",
    "\n",
    "            # Save results (image with detections)\n",
    "            if save_img:\n",
    "                if dataset.mode == 'image':\n",
    "                    cv2.imwrite(save_path, im0)\n",
    "                else:  # 'video' or 'stream'\n",
    "                    if vid_path[i] != save_path:  # new video\n",
    "                        vid_path[i] = save_path\n",
    "                        if isinstance(vid_writer[i], cv2.VideoWriter):\n",
    "                            vid_writer[i].release()  # release previous video writer\n",
    "                        if vid_cap:  # video\n",
    "                            fps = vid_cap.get(cv2.CAP_PROP_FPS)\n",
    "                            w = int(vid_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "                            h = int(vid_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "                        else:  # stream\n",
    "                            fps, w, h = 30, im0.shape[1], im0.shape[0]\n",
    "                        save_path = str(Path(save_path).with_suffix('.mp4'))  # force *.mp4 suffix on results videos\n",
    "                        vid_writer[i] = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))\n",
    "                    vid_writer[i].write(im0)\n",
    "\n",
    "        # Print time (inference-only)\n",
    "        LOGGER.info(f'{s}Done. ({t3 - t2:.3f}s)')\n",
    "\n",
    "    # Print results\n",
    "    t = tuple(x / seen * 1E3 for x in dt)  # speeds per image\n",
    "    LOGGER.info(f'Speed: %.1fms pre-process, %.1fms inference, %.1fms NMS per image at shape {(1, 3, *imgsz)}' % t)\n",
    "    if save_txt or save_img:\n",
    "        s = f\"\\n{len(list(save_dir.glob('labels/*.txt')))} labels saved to {save_dir / 'labels'}\" if save_txt else ''\n",
    "        LOGGER.info(f\"Results saved to {colorstr('bold', save_dir)}{s}\")\n",
    "    if update:\n",
    "        strip_optimizer(weights[0])  # update model (to fix SourceChangeWarning)\n",
    "run(\n",
    "        weights='E:/yolov5/runs/train/exp2/weights/best.pt',  # model.pt path(s)\n",
    "        source='data/images/test.jpg',  # file/dir/URL/glob, 0 for webcam\n",
    "        data='data/custom_data.yaml',  # dataset.yaml path\n",
    "        imgsz=(640, 640),  # inference size (height, width)\n",
    "        conf_thres=0.33,  # confidence threshold\n",
    "        iou_thres=0.45,  # NMS IOU threshold\n",
    "        max_det=1000,  # maximum detections per image\n",
    "        device='',  # cuda device, i.e. 0 or 0,1,2,3 or cpu\n",
    "        view_img=False,  # show results\n",
    "        save_txt=False,  # save results to *.txt\n",
    "        save_conf=False,  # save confidences in --save-txt labels\n",
    "        save_crop=True,  # save cropped prediction boxes\n",
    "        nosave=False,  # do not save images/videos\n",
    "        classes=None,  # filter by class: --class 0, or --class 0 2 3\n",
    "        agnostic_nms=False,  # class-agnostic NMS\n",
    "        augment=False,  # augmented inference\n",
    "        visualize=False,  # visualize features\n",
    "        update=False,  # update all models\n",
    "        project='/runs/detect/exp2',  # save results to project/name\n",
    "        #name='exp',  # save results to project/name\n",
    "        exist_ok=False,  # existing project/name ok, do not increment\n",
    "        line_thickness=3,  # bounding box thickness (pixels)\n",
    "        hide_labels=False,  # hide labels\n",
    "        hide_conf=False,  # hide confidences\n",
    "        half=False,  # use FP16 half-precision inference\n",
    "        dnn=False,  # use OpenCV DNN for ONNX inference\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name1 = 'E:/runs/detect/exp2/crops/tên người chuyển khoản'\n",
    "folder_name2 = 'E:/runs/detect/exp2/crops/tên người nhận'\n",
    "folder_name3 = 'E:/runs/detect/exp2/crops/STK nguồn'\n",
    "folder_name4 = 'E:/runs/detect/exp2/crops/STK đích'\n",
    "folder_name5 = 'E:/runs/detect/exp2/crops/nội dung chuyển khoản'\n",
    "folder_name6 = 'E:/runs/detect/exp2/crops/thời gian chuyển khoản'\n",
    "folder_name7 = 'E:/runs/detect/exp2/crops/số tiền'\n",
    "# Kiểm tra xem thư mục đã tồn tại hay chưa\n",
    "if not os.path.exists(folder_name1):\n",
    "    os.mkdir(folder_name1)\n",
    "if not os.path.exists(folder_name2):\n",
    "    os.mkdir(folder_name2)\n",
    "if not os.path.exists(folder_name3):\n",
    "    os.mkdir(folder_name3)\n",
    "if not os.path.exists(folder_name4):\n",
    "    os.mkdir(folder_name4)\n",
    "if not os.path.exists(folder_name5):\n",
    "    os.mkdir(folder_name5)    \n",
    "if not os.path.exists(folder_name6):\n",
    "    os.mkdir(folder_name6)\n",
    "if not os.path.exists(folder_name7):\n",
    "    os.mkdir(folder_name7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "old_folder_name1 = 'E:/runs/detect/exp2/crops/tên người nhận'\n",
    "new_folder_name2 = 'E:/runs/detect/exp2/crops/ten-nguoi-nhan'\n",
    "# Đổi tên thư mục\n",
    "os.rename(old_folder_name1, new_folder_name2)\n",
    "\n",
    "old_folder_name1 = 'E:/runs/detect/exp2/crops/tên người chuyển khoản'\n",
    "new_folder_name2 = 'E:/runs/detect/exp2/crops/ten-nguoi-chuyen-khoan'\n",
    "# Đổi tên thư mục\n",
    "os.rename(old_folder_name1, new_folder_name2)\n",
    "\n",
    "old_folder_name1 = 'E:/runs/detect/exp2/crops/STK nguồn'\n",
    "new_folder_name2 = 'E:/runs/detect/exp2/crops/STK-nguon'\n",
    "# Đổi tên thư mục\n",
    "os.rename(old_folder_name1, new_folder_name2)\n",
    "\n",
    "old_folder_name1 = 'E:/runs/detect/exp2/crops/STK đích'\n",
    "new_folder_name2 = 'E:/runs/detect/exp2/crops/STK-dich'\n",
    "# Đổi tên thư mục\n",
    "os.rename(old_folder_name1, new_folder_name2)\n",
    "\n",
    "old_folder_name1 = 'E:/runs/detect/exp2/crops/số tiền'\n",
    "new_folder_name2 = 'E:/runs/detect/exp2/crops/so-tien'\n",
    "# Đổi tên thư mục\n",
    "os.rename(old_folder_name1, new_folder_name2)\n",
    "\n",
    "old_folder_name1 = 'E:/runs/detect/exp2/crops/nội dung chuyển khoản'\n",
    "new_folder_name2 = 'E:/runs/detect/exp2/crops/noi-dung-chuyen-khoan'\n",
    "# Đổi tên thư mục\n",
    "os.rename(old_folder_name1, new_folder_name2)\n",
    "\n",
    "old_folder_name1 = 'E:/runs/detect/exp2/crops/thời gian chuyển khoản'\n",
    "new_folder_name2 = 'E:/runs/detect/exp2/crops/thoi-gian-chuyen-khoan'\n",
    "# Đổi tên thư mục\n",
    "os.rename(old_folder_name1, new_folder_name2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"nội dung chuyển khoản\": \"NGUYEN HOAI NAM\\nchuyen tien\", \"số tiền\": \"\", \"STK đích\": \"03269426688\", \"STK nguồn\": \"null\", \"tên người chuyển khoản\": \"null\", \"tên người nhận\": \"DOAN THỊ HONG NGOC\", \"thời gian chuyển khoản\": \"18:40 Thứ Sáu 05/05/2023\"}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "if os.path.exists('E:/runs/detect/exp2/crops/noi-dung-chuyen-khoan/test.jpg'):\n",
    "    image = cv2.imread('E:/runs/detect/exp2/crops/noi-dung-chuyen-khoan/test.jpg')\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Convert image to text\n",
    "    text1 = pytesseract.image_to_string(image, lang='vie', config='--psm 6')     \n",
    "else:\n",
    "    text1 = 'null'\n",
    "    \n",
    "if os.path.exists('E:/runs/detect/exp2/crops/so-tien/test.jpg'):\n",
    "    image = cv2.imread('E:/runs/detect/exp2/crops/so-tien/test.jpg')\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Convert image to text\n",
    "    text2 = pytesseract.image_to_string(image, lang='vie', config='--psm 6')\n",
    "else:\n",
    "    text2 = 'null'   \n",
    "\n",
    "if os.path.exists('E:/runs/detect/exp2/crops/STK-dich/test.jpg'):\n",
    "    image = cv2.imread('E:/runs/detect/exp2/crops/STK-dich/test.jpg')\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Convert image to text\n",
    "    text3 = pytesseract.image_to_string(image, lang='vie', config='--psm 6')\n",
    "else:\n",
    "    text3 = 'null'   \n",
    "\n",
    "if os.path.exists('E:/runs/detect/exp2/crops/STK-nguon/test.jpg'):\n",
    "    image = cv2.imread('E:/runs/detect/exp2/crops/STK-nguon/test.jpg')\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Convert image to text\n",
    "    text4 = pytesseract.image_to_string(image, lang='vie', config='--psm 6')\n",
    "else:\n",
    "    text4 = 'null'    \n",
    "\n",
    "if os.path.exists('E:/runs/detect/exp2/crops/ten-nguoi-chuyen-khoan/test.jpg'):\n",
    "    image = cv2.imread('E:/runs/detect/exp2/crops/ten-nguoi-chuyen-khoan/test.jpg')\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Convert image to text\n",
    "    text5 = pytesseract.image_to_string(image, lang='vie', config='--psm 6')\n",
    "else:\n",
    "    text5 = 'null'   \n",
    "\n",
    "if os.path.exists('E:/runs/detect/exp2/crops/ten-nguoi-nhan/test.jpg'):\n",
    "    image = cv2.imread('E:/runs/detect/exp2/crops/ten-nguoi-nhan/test.jpg')\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Convert image to text\n",
    "    text6 = pytesseract.image_to_string(image, lang='vie', config='--psm 6')\n",
    "else:\n",
    "    text6 = 'null'    \n",
    "\n",
    "if os.path.exists('E:/runs/detect/exp2/crops/thoi-gian-chuyen-khoan/test.jpg'):\n",
    "    image = cv2.imread('E:/runs/detect/exp2/crops/thoi-gian-chuyen-khoan/test.jpg')\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # Convert image to text\n",
    "    text7 = pytesseract.image_to_string(image, lang='vie', config='--psm 6')\n",
    "else:\n",
    "    text7 = 'null'   \n",
    "\n",
    "data = {\"nội dung chuyển khoản\": text1.strip(),\n",
    "        \"số tiền\": text2.strip(),\n",
    "        \"STK đích\": text3.strip(),\n",
    "        \"STK nguồn\": text4.strip(),\n",
    "        \"tên người chuyển khoản\": text5.strip(),\n",
    "        \"tên người nhận\": text6.strip(),\n",
    "        \"thời gian chuyển khoản\": text7.strip()}\n",
    "json_data = json.dumps(data, ensure_ascii=False)\n",
    "print(json_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
